# YOLOv11 Segmentation - Silage Bale Detection

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.7+](https://img.shields.io/badge/pytorch-2.7+-red.svg)](https://pytorch.org/)
[![Ultralytics 8.3+](https://img.shields.io/badge/ultralytics-8.3+-green.svg)](https://github.com/ultralytics/ultralytics)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

ê³¤í¬ì‚¬ì¼ë¦¬ì§€(Silage Bale) ìë™ ê²€ì¶œ ë° ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œìŠ¤í…œ

> ğŸš€ **ì²˜ìŒ ì‹œì‘í•˜ì‹œë‚˜ìš”?** [`START_HERE.md`](START_HERE.md) íŒŒì¼ì„ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”!

[English](#english) | [í•œêµ­ì–´](#í•œêµ­ì–´)

---

## í•œêµ­ì–´

### ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

ë“œë¡ /ìœ„ì„± ì´¬ì˜ ì´ë¯¸ì§€ì—ì„œ ê³¤í¬ì‚¬ì¼ë¦¬ì§€ë¥¼ ìë™ìœ¼ë¡œ ê²€ì¶œí•˜ê³  ì„¸ê·¸ë©˜í…Œì´ì…˜í•˜ì—¬ ì¬ê³  ê´€ë¦¬ ë° ë¬¼ëŸ‰ íŒŒì•…ì„ ìë™í™”í•˜ëŠ” AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### âœ¨ ì£¼ìš” ê¸°ëŠ¥

- **ê³ ì •ë°€ ê²€ì¶œ**: mAP50 92.2% (ëª©í‘œ 75-85% ì´ˆê³¼ ë‹¬ì„±)
- **ì‹¤ì‹œê°„ ì¶”ë¡ **: 11.3ms/ì´ë¯¸ì§€ (~36 FPS)
- **ìë™ ì¹´ìš´íŒ…**: ê°ì²´ ê°œìˆ˜ ìë™ ì§‘ê³„
- **4-band ì´ë¯¸ì§€ ì§€ì›**: TIF (R,G,B,NIR) â†’ RGB ìë™ ë³€í™˜
- **ì™„ì „ ìë™í™”**: ì „ì²˜ë¦¬ â†’ í•™ìŠµ â†’ ì¶”ë¡  íŒŒì´í”„ë¼ì¸

### ğŸ¯ ì„±ëŠ¥ ì§€í‘œ

| ë©”íŠ¸ë¦­ | ê°’ | í‰ê°€ |
|--------|-----|------|
| **mAP50 (Mask)** | 92.2% | â­â­â­ ìš°ìˆ˜ |
| **mAP50-95 (Mask)** | 85.3% | â­â­â­ ìš°ìˆ˜ |
| **Precision** | 96.5% | â­â­â­ ë§¤ìš° ë†’ìŒ |
| **Recall** | 86.3% | â­â­ ì–‘í˜¸ |
| **ì¶”ë¡  ì†ë„** | 11.3ms | â­â­â­ ì‹¤ì‹œê°„ |
| **ê²€ì¶œë¥ ** | 97% | â­â­â­ ìš°ìˆ˜ |

### ğŸš€ ë¹ ë¥¸ ì‹œì‘

#### 1. í™˜ê²½ ì„¤ì •

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/YOUR_USERNAME/dbwjdakrso4235-sys.git
cd dbwjdakrso4235-sys

# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
pip install ultralytics opencv-python rasterio numpy matplotlib tensorboard tqdm pyyaml
```

#### 2. ë°ì´í„° ì „ì²˜ë¦¬

```bash
# 4-band TIF â†’ RGB PNG ë³€í™˜
python scripts/preprocess_dataset.py \
    --input E:/namwon_ai/dataset_silage_bale \
    --output E:/namwon_ai/dataset_silage_bale_rgb \
    --format png
```

#### 3. ëª¨ë¸ í•™ìŠµ

```bash
# Optimized ì„¤ì •ìœ¼ë¡œ í•™ìŠµ
python scripts/train.py \
    --data E:/namwon_ai/dataset_silage_bale_rgb/dataset.yaml \
    --model n \
    --epochs 150 \
    --batch 8 \
    --imgsz 1024 \
    --lr0 0.001 \
    --optimizer AdamW \
    --patience 100 \
    --name silage_optimized

# ë˜ëŠ” YAML ì„¤ì • íŒŒì¼ ì‚¬ìš©
yolo segment train data=configs/train_optimized.yaml
```

#### 4. ì¶”ë¡ 

```bash
# ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ 
python scripts/inference.py \
    --model runs/segment/silage_optimized/weights/best.pt \
    --source path/to/image.jpg \
    --imgsz 1024 \
    --save

# ë°°ì¹˜ ì¶”ë¡  (í´ë”)
python scripts/inference.py \
    --model runs/segment/silage_optimized/weights/best.pt \
    --source path/to/images/ \
    --imgsz 1024 \
    --save --save-txt --analyze
```

### ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
dbwjdakrso4235-sys/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ train_optimized.yaml      # ìµœì í™”ëœ í•™ìŠµ ì„¤ì •
â”‚   â””â”€â”€ train_advanced.yaml       # Advanced ëª¨ë¸ ì„¤ì •
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py                  # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ inference.py              # ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ preprocess_dataset.py    # ë°ì´í„° ì „ì²˜ë¦¬
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ preprocess.py             # ì „ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ inference_system/             # â­ ê³¤í¬ì‚¬ì¼ë¦¬ì§€ ì¶”ë¡  ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ crop_processor.py    # SHP ê¸°ë°˜ TIF í¬ë¡­
â”‚   â”‚   â”œâ”€â”€ inference_engine.py  # YOLO ì¶”ë¡  ì—”ì§„
â”‚   â”‚   â””â”€â”€ pipeline.py          # í†µí•© íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ examples/
â”‚   â”‚   â”œâ”€â”€ test_crop.py
â”‚   â”‚   â”œâ”€â”€ test_inference.py
â”‚   â”‚   â”œâ”€â”€ test_valid_polygons.py
â”‚   â”‚   â””â”€â”€ test_full_pipeline.py
â”‚   â”œâ”€â”€ output/                   # ì¶”ë¡  ê²°ê³¼
â”‚   â””â”€â”€ README.md                 # ì‹œìŠ¤í…œ ê°€ì´ë“œ
â”œâ”€â”€ Dev_md/
â”‚   â”œâ”€â”€ 01_ê·œì¹™_Rules.md         # ê°œë°œ ê·œì¹™
â”‚   â”œâ”€â”€ 02_ê°€ì´ë“œ_Guide.md       # ì‚¬ìš© ê°€ì´ë“œ
â”‚   â”œâ”€â”€ 03_ê°œë°œì¼ì§€_DevLog_20251022.md
â”‚   â”œâ”€â”€ 06_í•˜ì´í¼íŒŒë¼ë¯¸í„°_ìµœì í™”.md
â”‚   â”œâ”€â”€ 07_ìµœì¢…ë³´ê³ ì„œ_Final_Report.md
â”‚   â”œâ”€â”€ 08_í–¥í›„ê³„íš_Future_Roadmap.md
â”‚   â”œâ”€â”€ 09_ê³¤í¬ì‚¬ì¼ë¦¬ì§€_ì¶”ë¡ ì‹œìŠ¤í…œ_ê°œë°œê³„íš.md  # â­ ì¶”ë¡  ì‹œìŠ¤í…œ ì„¤ê³„
â”‚   â””â”€â”€ claude.md                 # Claude ì‘ì—… ë¶„ë‹´
â”œâ”€â”€ runs/                         # í•™ìŠµ/ì¶”ë¡  ê²°ê³¼
â”œâ”€â”€ README.md                     # ë³¸ ë¬¸ì„œ
â””â”€â”€ .gitignore
```

### ğŸ“Š ë°ì´í„°ì…‹

- **ì´ ì´ë¯¸ì§€**: 324ê°œ
  - Train: 259 (79.9%)
  - Val: 32 (9.9%)
  - Test: 33 (10.2%)
- **ì´ ê°ì²´**: 970ê°œ
- **í´ë˜ìŠ¤**: 1 (ê³¤í¬ì‚¬ì¼ë¦¬ì§€)
- **í•´ìƒë„**: 1024 x 1024 pixels
- **í¬ë§·**: 4-band TIF (R,G,B,NIR) â†’ RGB PNG

### ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„°

#### ìµœì í™”ëœ ì„¤ì • (Optimized)
```yaml
model: yolo11n-seg
epochs: 150
batch: 8
imgsz: 1024
lr0: 0.001
optimizer: AdamW
weight_decay: 0.001

# Augmentation
mixup: 0.15
copy_paste: 0.3
mosaic: 1.0
degrees: 10.0
```

ìì„¸í•œ ì„¤ì •ì€ [`configs/train_optimized.yaml`](configs/train_optimized.yaml) ì°¸ì¡°

### ğŸ“ˆ í•™ìŠµ ê²°ê³¼

#### í•™ìŠµ ê³¡ì„ 
```
Epoch   1:   0.5% mAP50
Epoch   2:  31.2% mAP50 (65ë°° ì¦ê°€!)
Epoch  50:  80.3% mAP50 (ëª©í‘œ ë‹¬ì„±)
Epoch 100:  89.4% mAP50
Epoch 150:  92.2% mAP50 (ìµœì¢…)
```

#### Loss ìˆ˜ë ´
| Loss | ì´ˆê¸° | ìµœì¢… | ê°ì†Œìœ¨ |
|------|------|------|--------|
| box_loss | 1.188 | 0.372 | 68.7% |
| seg_loss | 2.273 | 0.509 | 77.6% |
| cls_loss | 3.411 | 0.347 | 89.8% |

í•™ìŠµ ê³¡ì„  ë° ìƒì„¸ ë¶„ì„ì€ [`runs/segment/silage_optimized/results.png`](runs/segment/silage_optimized/results.png) ì°¸ì¡°

### ğŸ¯ ì¶”ë¡  ê²°ê³¼

#### Test ì„¸íŠ¸ í‰ê°€
- **ì´ ì´ë¯¸ì§€**: 33ê°œ
- **ê²€ì¶œ ì„±ê³µ**: 32ê°œ (97%)
- **ê²€ì¶œ ì‹¤íŒ¨**: 1ê°œ (3%)
- **ì´ ê²€ì¶œ ê°ì²´**: 120ê°œ
- **í‰ê·  Confidence**: 84.4%
- **ì¶”ë¡  ì†ë„**: 11.3ms/ì´ë¯¸ì§€

#### ê°œìˆ˜ë³„ ë¶„í¬
| ê²€ì¶œ ê°œìˆ˜ | ì´ë¯¸ì§€ ìˆ˜ | ë¹„ìœ¨ |
|----------|----------|------|
| 1ê°œ | 9ì¥ | 28.1% |
| 2ê°œ | 10ì¥ | 31.3% |
| 3-5ê°œ | 10ì¥ | 31.3% |
| 7ê°œ ì´ìƒ | 3ì¥ | 9.4% |
| ìµœëŒ€ | 31ê°œ | - |

### ğŸ—ºï¸ ê³¤í¬ì‚¬ì¼ë¦¬ì§€ ì¶”ë¡  ì‹œìŠ¤í…œ (NEW!)

ëŒ€ìš©ëŸ‰ TIF ì´ë¯¸ì§€ì™€ Shapefileì„ í™œìš©í•œ ì§€ë¦¬ê³µê°„ ê¸°ë°˜ ê³¤í¬ì‚¬ì¼ë¦¬ì§€ ìë™ ê²€ì¶œ ì‹œìŠ¤í…œ

#### ì£¼ìš” ê¸°ëŠ¥
- **SHP ê¸°ë°˜ ì„ íƒì  ì²˜ë¦¬**: Shapefileë¡œ ì •ì˜ëœ ì˜ì—­ë§Œ í¬ë¡­í•˜ì—¬ ì²˜ë¦¬ íš¨ìœ¨ ê·¹ëŒ€í™”
- **ëŒ€ìš©ëŸ‰ TIF ì§€ì›**: 25.8GB TIF íŒŒì¼ì„ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ì§€ ì•Šê³  ë¶€ë¶„ ì½ê¸°
- **GeoPackage ì¶œë ¥**: ê²€ì¶œ ê²°ê³¼ë¥¼ ì§€ë¦¬ ì¢Œí‘œê³„ì™€ í•¨ê»˜ ì €ì¥
- **ìë™ í†µê³„ ìƒì„±**: JSON, CSV, TXT í˜•ì‹ì˜ ìƒì„¸ ë³´ê³ ì„œ ìë™ ìƒì„±

#### ë¹ ë¥¸ ì‹œì‘

```bash
# ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
python inference_system/examples/test_full_pipeline.py

# ë˜ëŠ” ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©
python inference_system/src/pipeline.py \
    --tif F:/namwon_ai/input_tif/ê¸ˆì§€ë©´_1ì°¨.tif \
    --shp F:/namwon_ai/saryo_jeongbo/saryo_parcel.shp \
    --model runs/segment/silage_optimized/weights/best.pt \
    --output inference_system/output
```

#### ì‹œìŠ¤í…œ ì„±ëŠ¥
- **í¬ë¡­ ì†ë„**: 100ê°œ/ë¶„ (ëª©í‘œ 50ê°œ/ë¶„ì˜ 2ë°°)
- **ì¶”ë¡  ì†ë„**: 0.6ì´ˆ/í´ë¦¬ê³¤
- **ì²˜ë¦¬ ì„±ê³µë¥ **: 100% (15/15 í´ë¦¬ê³¤)
- **ë©”ëª¨ë¦¬ íš¨ìœ¨**: ëŒ€ìš©ëŸ‰ TIFë¥¼ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ì§€ ì•Šê³  ì²˜ë¦¬

#### ì¶œë ¥ í˜•ì‹
```
output/
â”œâ”€â”€ silage_bale_detections.gpkg    # GeoPackage (ì¢Œí‘œê³„ ë³´ì¡´)
â”œâ”€â”€ visualizations/                 # ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”
â””â”€â”€ reports/
    â”œâ”€â”€ statistics.json             # ì „ì²´ í†µê³„
    â”œâ”€â”€ polygon_details.csv         # í´ë¦¬ê³¤ë³„ ìƒì„¸
    â””â”€â”€ summary.txt                 # ìš”ì•½ ë³´ê³ ì„œ
```

ìƒì„¸ ê°€ì´ë“œ: [`inference_system/README.md`](inference_system/README.md)

### ğŸ’» ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

#### ìµœì†Œ ì‚¬ì–‘
- **OS**: Windows 10/11, Ubuntu 20.04+, macOS 12+
- **Python**: 3.10+
- **GPU**: NVIDIA GPU (4GB+ VRAM)
- **CUDA**: 11.8+
- **RAM**: 8GB+
- **ì €ì¥ê³µê°„**: 10GB+

#### ê¶Œì¥ ì‚¬ì–‘
- **GPU**: NVIDIA RTX 3060 ì´ìƒ (8GB+ VRAM)
- **RAM**: 16GB+
- **ì €ì¥ê³µê°„**: 20GB+

### ğŸ“š ë¬¸ì„œ

- **ì‚¬ìš© ê°€ì´ë“œ**: [`Dev_md/02_ê°€ì´ë“œ_Guide.md`](Dev_md/02_ê°€ì´ë“œ_Guide.md)
- **ê°œë°œ ê·œì¹™**: [`Dev_md/01_ê·œì¹™_Rules.md`](Dev_md/01_ê·œì¹™_Rules.md)
- **ê°œë°œ ì¼ì§€**: [`Dev_md/03_ê°œë°œì¼ì§€_DevLog_20251022.md`](Dev_md/03_ê°œë°œì¼ì§€_DevLog_20251022.md)
- **í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”**: [`Dev_md/06_í•˜ì´í¼íŒŒë¼ë¯¸í„°_ìµœì í™”.md`](Dev_md/06_í•˜ì´í¼íŒŒë¼ë¯¸í„°_ìµœì í™”.md)
- **ìµœì¢… ë³´ê³ ì„œ**: [`Dev_md/07_ìµœì¢…ë³´ê³ ì„œ_Final_Report.md`](Dev_md/07_ìµœì¢…ë³´ê³ ì„œ_Final_Report.md)
- **í–¥í›„ ê³„íš**: [`Dev_md/08_í–¥í›„ê³„íš_Future_Roadmap.md`](Dev_md/08_í–¥í›„ê³„íš_Future_Roadmap.md)

### ğŸ› ï¸ ì£¼ìš” ëª…ë ¹ì–´

```bash
# í•™ìŠµ
python scripts/train.py --data <dataset.yaml> --model n --epochs 150

# ì¶”ë¡ 
python scripts/inference.py --model <model.pt> --source <images/>

# TensorBoard ëª¨ë‹ˆí„°ë§
tensorboard --logdir runs/segment

# ëª¨ë¸ ê²€ì¦
yolo segment val model=<model.pt> data=<dataset.yaml>
```

### ğŸ”¬ ê¸°ìˆ  ìŠ¤íƒ

| ì¹´í…Œê³ ë¦¬ | ê¸°ìˆ  |
|---------|------|
| **Deep Learning** | PyTorch 2.7.1, Ultralytics YOLOv11 |
| **Computer Vision** | OpenCV 4.12.0, rasterio 1.4.3 |
| **Scientific Computing** | NumPy 2.1.2, Matplotlib 3.10.7 |
| **Monitoring** | TensorBoard 2.20.0 |
| **GPU** | CUDA 11.8, cuDNN |

### ğŸš€ í–¥í›„ ê³„íš

#### ë‹¨ê¸° (1-2ì£¼)
- [ ] Advanced ëª¨ë¸ í•™ìŠµ (yolo11s-seg)
- [ ] API ì„œë²„ êµ¬ì¶• (FastAPI)
- [ ] Docker íŒ¨í‚¤ì§•

#### ì¤‘ê¸° (1-2ê°œì›”)
- [ ] NIR ë°´ë“œ í™œìš© ì—°êµ¬
- [ ] ì›¹ ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶•
- [ ] ëª¨ë¸ ìµœì í™” (ONNX/TensorRT)

#### ì¥ê¸° (3ê°œì›”+)
- [ ] ë‹¤ì¤‘ ì‘ë¬¼ ì§€ì›
- [ ] ì‹œê³„ì—´ ë¶„ì„
- [ ] ëª¨ë°”ì¼ ì•± ê°œë°œ

ìì„¸í•œ ë¡œë“œë§µì€ [`Dev_md/08_í–¥í›„ê³„íš_Future_Roadmap.md`](Dev_md/08_í–¥í›„ê³„íš_Future_Roadmap.md) ì°¸ì¡°

### ğŸ¤ ê¸°ì—¬

ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤! Pull Requestë¥¼ ë³´ë‚´ì£¼ì„¸ìš”.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### ğŸ“„ ë¼ì´ì„¼ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„¼ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

### ğŸ‘¥ ê°œë°œíŒ€

- **AI Development**: Claude Sonnet 4.5
- **Project Management**: LX
- **Documentation**: AI Team

### ğŸ™ ê°ì‚¬ì˜ ë§

- [Ultralytics](https://github.com/ultralytics/ultralytics) - YOLOv11 í”„ë ˆì„ì›Œí¬
- [PyTorch](https://pytorch.org/) - ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
- [rasterio](https://rasterio.readthedocs.io/) - ì§€ë¦¬ê³µê°„ ì´ë¯¸ì§€ ì²˜ë¦¬

### ğŸ“ ì—°ë½ì²˜

í”„ë¡œì íŠ¸ ê´€ë ¨ ë¬¸ì˜: [ì´ìŠˆ ë“±ë¡](https://github.com/YOUR_USERNAME/dbwjdakrso4235-sys/issues)

---

## English

### ğŸ“‹ Project Overview

An AI system for automatic detection and segmentation of silage bales from drone/satellite imagery for automated inventory management and quantity assessment.

### âœ¨ Key Features

- **High-Precision Detection**: 92.2% mAP50 (exceeding 75-85% target)
- **Real-time Inference**: 11.3ms/image (~36 FPS)
- **Automatic Counting**: Automated object counting
- **4-band Image Support**: TIF (R,G,B,NIR) â†’ RGB automatic conversion
- **Fully Automated**: End-to-end preprocessing â†’ training â†’ inference pipeline

### ğŸ¯ Performance Metrics

| Metric | Value | Rating |
|--------|-------|--------|
| **mAP50 (Mask)** | 92.2% | â­â­â­ Excellent |
| **mAP50-95 (Mask)** | 85.3% | â­â­â­ Excellent |
| **Precision** | 96.5% | â­â­â­ Very High |
| **Recall** | 86.3% | â­â­ Good |
| **Inference Speed** | 11.3ms | â­â­â­ Real-time |
| **Detection Rate** | 97% | â­â­â­ Excellent |

### ğŸš€ Quick Start

#### 1. Setup Environment

```bash
# Clone repository
git clone https://github.com/YOUR_USERNAME/dbwjdakrso4235-sys.git
cd dbwjdakrso4235-sys

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
pip install ultralytics opencv-python rasterio numpy matplotlib tensorboard tqdm pyyaml
```

#### 2. Data Preprocessing

```bash
# Convert 4-band TIF â†’ RGB PNG
python scripts/preprocess_dataset.py \
    --input E:/namwon_ai/dataset_silage_bale \
    --output E:/namwon_ai/dataset_silage_bale_rgb \
    --format png
```

#### 3. Train Model

```bash
# Train with optimized settings
python scripts/train.py \
    --data E:/namwon_ai/dataset_silage_bale_rgb/dataset.yaml \
    --model n \
    --epochs 150 \
    --batch 8 \
    --imgsz 1024 \
    --lr0 0.001 \
    --optimizer AdamW \
    --patience 100 \
    --name silage_optimized

# Or use YAML config
yolo segment train data=configs/train_optimized.yaml
```

#### 4. Run Inference

```bash
# Single image inference
python scripts/inference.py \
    --model runs/segment/silage_optimized/weights/best.pt \
    --source path/to/image.jpg \
    --imgsz 1024 \
    --save

# Batch inference (folder)
python scripts/inference.py \
    --model runs/segment/silage_optimized/weights/best.pt \
    --source path/to/images/ \
    --imgsz 1024 \
    --save --save-txt --analyze
```

### ğŸ“š Documentation

For detailed documentation, see [`Dev_md/`](Dev_md/) directory:
- Usage Guide (Korean)
- Development Log (Korean)
- Hyperparameter Optimization (Korean)
- Final Report (Korean)
- Future Roadmap (Korean)

### ğŸ’» System Requirements

#### Minimum
- **OS**: Windows 10/11, Ubuntu 20.04+, macOS 12+
- **Python**: 3.10+
- **GPU**: NVIDIA GPU (4GB+ VRAM)
- **CUDA**: 11.8+
- **RAM**: 8GB+

#### Recommended
- **GPU**: NVIDIA RTX 3060+ (8GB+ VRAM)
- **RAM**: 16GB+
- **Storage**: 20GB+

### ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### ğŸ“ Contact

For inquiries: [Create an issue](https://github.com/YOUR_USERNAME/dbwjdakrso4235-sys/issues)

---

**Made with â¤ï¸ by AI Development Team**
